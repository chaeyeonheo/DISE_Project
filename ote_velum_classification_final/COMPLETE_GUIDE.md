# ğŸ“š OTE/Velum ë¶„ë¥˜ ëª¨ë¸ - ì™„ì „ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ¯ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ìˆ˜ë©´ ë¬´í˜¸í¡ ê²€ì‚¬(DISE) ë¹„ë””ì˜¤ì—ì„œ OTE, Velum, None ì˜ì—­ì„ ìë™ ë¶„ë¥˜í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
project/
â”œâ”€â”€ dataset/                          # ì›ë³¸ ë¹„ë””ì˜¤ (ì‚¬ìš©ìê°€ ì¤€ë¹„)
â”‚   â”œâ”€â”€ OTE/
â”‚   â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”‚   â””â”€â”€ video2.mp4
â”‚   â””â”€â”€ Velum/
â”‚       â”œâ”€â”€ video1.mp4
â”‚       â””â”€â”€ video2.mp4
â”‚
â”œâ”€â”€ processed_dataset/                # ì „ì²˜ë¦¬ í›„ ìƒì„±ë¨
â”‚   â”œâ”€â”€ OTE/                         # OTE í”„ë ˆì„ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ Velum/                       # Velum í”„ë ˆì„ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ None/                        # None í”„ë ˆì„ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ annotations.json             # ì „ì²´ ë ˆì´ë¸” ì •ë³´
â”‚   â””â”€â”€ visualizations/              # ë¶„ì„ ê·¸ë˜í”„
â”‚       â”œâ”€â”€ video1_analysis.png
â”‚       â””â”€â”€ video2_analysis.png
â”‚
â”œâ”€â”€ checkpoints/                      # í•™ìŠµ í›„ ìƒì„±ë¨
â”‚   â”œâ”€â”€ best_model.pth               # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”œâ”€â”€ training_history.json
â”‚   â””â”€â”€ confusion_matrix.png
â”‚
â””â”€â”€ [ì½”ë“œ íŒŒì¼ë“¤]
    â”œâ”€â”€ preprocess_videos_robust.py  # ì „ì²˜ë¦¬ (ì¶”ì²œ)
    â”œâ”€â”€ dataset.py
    â”œâ”€â”€ model.py
    â”œâ”€â”€ train.py
    â”œâ”€â”€ inference.py
    â””â”€â”€ requirements.txt
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (5ë‹¨ê³„)

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„

```bash
# í´ë” êµ¬ì¡° ìƒì„±
mkdir -p dataset/OTE dataset/Velum

# ë¹„ë””ì˜¤ íŒŒì¼ì„ í•´ë‹¹ í´ë”ì— ë³µì‚¬
# dataset/OTE/ ì— OTE ë¹„ë””ì˜¤ë“¤
# dataset/Velum/ ì— Velum ë¹„ë””ì˜¤ë“¤
```

### 3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ â­ ì¤‘ìš”!

```bash
# ë°©ë²• 1: Robust ì „ì²˜ë¦¬ (ì¶”ì²œ) - ìë™ ê²€ì‚¬ êµ¬ê°„ ê°ì§€
python preprocess_videos_robust.py

# ê²°ê³¼ í™•ì¸
ls processed_dataset/               # í”„ë ˆì„ ì´ë¯¸ì§€ë“¤
ls processed_dataset/visualizations/  # ë¶„ì„ ê·¸ë˜í”„ë“¤
```

**ì¤‘ìš”**: `visualizations` í´ë”ì˜ ê·¸ë˜í”„ë“¤ì„ **ê¼­ í™•ì¸**í•˜ì„¸ìš”!
- ê° ë¹„ë””ì˜¤ì˜ í’ˆì§ˆ í”„ë¡œíŒŒì¼ê³¼ ìë™ ê°ì§€ëœ ê²€ì‚¬ êµ¬ê°„ í™•ì¸
- ì´ìƒí•œ íŒ¨í„´ì´ ìˆìœ¼ë©´ ìˆ˜ë™ ì¡°ì • í•„ìš”

### 4ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ

```bash
python train.py
```

í•™ìŠµ ì¤‘ ì¶œë ¥:
```
Epoch 1/50
Train Loss: 0.8234 | Train Acc: 65.43%
Val Loss: 0.7156 | Val Acc: 71.22%
âœ“ Best model saved with val_acc: 71.22%
```

### 5ë‹¨ê³„: ì¶”ë¡ 

```bash
# ë¹„ë””ì˜¤ ë¶„ì„
python inference.py \
    --model checkpoints/best_model.pth \
    --input test_video.mp4 \
    --visualize

# ê²°ê³¼ í™•ì¸
# - results.json: í”„ë ˆì„ë³„ ì˜ˆì¸¡ ê²°ê³¼
# - test_video_predictions.mp4: ì‹œê°í™”ëœ ë¹„ë””ì˜¤
```

---

## ğŸ“Š ì „ì²˜ë¦¬ ìƒì„¸ ê°€ì´ë“œ

### Robust ì „ì²˜ë¦¬ì˜ íŠ¹ì§•

**6ê°€ì§€ ì§€í‘œë¥¼ ì¢…í•© ë¶„ì„**:

1. **ë°ê¸° (Brightness)**: í™”ë©´ì˜ í‰ê·  ë°ê¸°
2. **ì„ ëª…ë„ (Sharpness)**: Laplacian varianceë¡œ ì¸¡ì •
3. **ëŒ€ë¹„ (Contrast)**: í”½ì…€ ê°’ì˜ í‘œì¤€í¸ì°¨
4. **ì—£ì§€ ë°€ë„ (Edge Density)**: Canny edge ë¹„ìœ¨
5. **ìƒ‰ìƒ ë¶„ì‚° (Color Variance)**: RGB ì±„ë„ í‘œì¤€í¸ì°¨
6. **ì›€ì§ì„ (Motion)**: í”„ë ˆì„ ê°„ ì°¨ì´

**ì¢…í•© ì ìˆ˜ ê³„ì‚°**:
```python
combined_score = (
    0.25 Ã— brightness +
    0.25 Ã— sharpness +
    0.20 Ã— contrast +
    0.15 Ã— edge_density +
    0.10 Ã— color_variance +
    0.05 Ã— (1 - motion)  # ì›€ì§ì„ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
)
```

### 3ê°€ì§€ ê²€ì‚¬ êµ¬ê°„ ê°ì§€ ë°©ë²•

#### 1) threshold (ë¹ ë¦„)
```bash
python preprocess_videos_robust.py --method threshold
```
- ì¢…í•© ì ìˆ˜ê°€ 0.6 ì´ìƒì¸ êµ¬ê°„ì„ ê²€ì‚¬ êµ¬ê°„ìœ¼ë¡œ ê°„ì£¼
- ê°€ì¥ ë¹ ë¥´ì§€ë§Œ ë‹¨ìˆœí•¨

#### 2) derivative (ì¤‘ê°„)
```bash
python preprocess_videos_robust.py --method derivative
```
- ì ìˆ˜ì˜ ë³€í™”ìœ¨(1ì°¨ ë¯¸ë¶„) ë¶„ì„
- ê¸‰ìƒìŠ¹ ì§€ì  = ê²€ì‚¬ ì‹œì‘
- ê¸‰í•˜ê°• ì§€ì  = ê²€ì‚¬ ì¢…ë£Œ

#### 3) combined (ê¶Œì¥) â­
```bash
python preprocess_videos_robust.py --method combined
```
- ì ì‘í˜• ì„ê³„ê°’ + ì—°ì†ì„± ë¶„ì„
- ê°€ì¥ ê¸´ ê³ í’ˆì§ˆ êµ¬ê°„ì„ ê²€ì‚¬ êµ¬ê°„ìœ¼ë¡œ ì„ íƒ
- **ê°€ì¥ robustí•˜ê³  ì •í™•í•¨**

### ì‹œê°í™” ê·¸ë˜í”„ ì½ëŠ” ë²•

ìƒì„±ëœ ê·¸ë˜í”„ (`processed_dataset/visualizations/*.png`)ë¥¼ í™•ì¸í•˜ì„¸ìš”:

```
[ê·¸ë˜í”„ êµ¬ì„±]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Brightness   â”‚ Sharpness    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Contrast     â”‚ Edge Density â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Color Var    â”‚ Motion       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Combined     â”‚ Detection    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì´ˆë¡ ì„¸ë¡œì„  = ê²€ì‚¬ ì‹œì‘
ë¹¨ê°• ì„¸ë¡œì„  = ê²€ì‚¬ ì¢…ë£Œ
```

**ì¢‹ì€ ì˜ˆì‹œ**:
```
Combined Score
1.0 â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
0.8 â”‚         â”‚  ê²€ì‚¬ êµ¬ê°„    â”‚
0.6 â”‚     â”Œâ”€â”€â”€â”¤              â”œâ”€â”€â”€â”
0.4 â”‚  â”Œâ”€â”€â”˜   â”‚              â”‚   â””â”€â”€â”
0.2 â”‚â”€â”€â”˜      â”‚              â”‚      â””â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
    ì‚½ì…      ê²€ì‚¬ ì‹œì‘      ê²€ì‚¬ ë    ì œê±°
```

**ë‚˜ìœ ì˜ˆì‹œ** (ìˆ˜ë™ í™•ì¸ í•„ìš”):
```
Combined Score
1.0 â”‚ â”Œâ”€â”€â”    â”Œâ”€â”€â”    â”Œâ”€â”€â”
0.8 â”‚ â”‚  â”‚    â”‚  â”‚    â”‚  â”‚  â† ê³„ì† ë³€ë™
0.6 â”‚â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
    (ê²€ì‚¬ êµ¬ê°„ ë¶ˆëª…í™•)
```

---

## âš™ï¸ ì£¼ìš” ì„¤ì • ì¡°ì •

### ì „ì²˜ë¦¬ ì„¤ì •

```bash
# ì‹œê°í™” ë„ê¸° (ë¹ ë¥¸ ì²˜ë¦¬)
python preprocess_videos_robust.py --no-viz

# ë‹¤ë¥¸ ê°ì§€ ë°©ë²• ì‹œë„
python preprocess_videos_robust.py --method threshold
python preprocess_videos_robust.py --method derivative
```

### í•™ìŠµ ì„¤ì •

`train.py` íŒŒì¼ ìˆ˜ì •:

```python
config = {
    'model_name': 'resnet50',        # 'resnet18', 'efficientnet_b0'
    'batch_size': 32,                # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
    'epochs': 50,                    # ë” ê¸¸ê²Œ/ì§§ê²Œ
    'learning_rate': 1e-4,           # í•™ìŠµë¥ 
    'img_size': 224,                 # ì´ë¯¸ì§€ í¬ê¸°
}
```

### ì¶”ë¡  ì„¤ì •

```bash
# í”„ë ˆì„ ê°„ê²© ì¡°ì • (ë¹ ë¥¸ ì²˜ë¦¬)
python inference.py \
    --model checkpoints/best_model.pth \
    --input video.mp4 \
    --frame-interval 5  # 5í”„ë ˆì„ë§ˆë‹¤ 1ê°œë§Œ ë¶„ì„

# ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ (3ì´ˆ ë‹¨ìœ„)
python inference.py \
    --model checkpoints/best_model.pth \
    --input video.mp4 \
    --segment-analysis \
    --segment-duration 3.0
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²° (Troubleshooting)

### ë¬¸ì œ 1: ì „ì²˜ë¦¬ ì‹œ "ê²€ì‚¬ êµ¬ê°„ì´ ì´ìƒí•¨"

**ì¦ìƒ**: ì‹œê°í™”ë¥¼ ë³´ë‹ˆ ê²€ì‚¬ êµ¬ê°„ì´ ì˜ëª» ê°ì§€ë¨

**í•´ê²°**:
```python
# preprocess_videos_robust.py ìˆ˜ì •
# detect_examination_period í•¨ìˆ˜ ë‚´ë¶€

# ì„ê³„ê°’ ì¡°ì •
adaptive_threshold = median_score + 0.5 * std_score  # 0.5ë¥¼ 0.3~0.7ë¡œ ì¡°ì •

# ë˜ëŠ” ë‹¤ë¥¸ ê°ì§€ ë°©ë²• ì‹œë„
python preprocess_videos_robust.py --method threshold
```

### ë¬¸ì œ 2: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**: `CUDA out of memory`

**í•´ê²°**:
```python
# train.py ìˆ˜ì •
config['batch_size'] = 16  # 32 â†’ 16 â†’ 8
config['img_size'] = 128   # 224 â†’ 128

# ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
config['model_name'] = 'resnet18'  # resnet50 ëŒ€ì‹ 
```

### ë¬¸ì œ 3: None í´ë˜ìŠ¤ ì„±ëŠ¥ì´ ë‚®ìŒ

**ì¦ìƒ**: Confusion matrixì—ì„œ None ì˜¤ë¶„ë¥˜ê°€ ë§ìŒ

**í•´ê²°**:

1. **ë” ë§ì€ None ë°ì´í„° ìˆ˜ì§‘**
```bash
# ë³„ë„ None ë¹„ë””ì˜¤ ì¶”ê°€
mkdir dataset/None
# ì‚½ì…/ì œê±° ê³¼ì •ë§Œ ë‹´ì€ ë¹„ë””ì˜¤ë“¤ ì¶”ê°€
```

2. **frame_interval ì¡°ì •**
```python
# preprocess_videos_robust.py ìˆ˜ì •
# extract_frames í˜¸ì¶œ ì‹œ
frame_interval=2  # ë” ì‘ê²Œ (ë” ë§ì€ None í”„ë ˆì„)
```

3. **Class Weight ì‚¬ìš©**
```python
# train.pyì— ì¶”ê°€
from torch.nn import CrossEntropyLoss

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
class_counts = [len_ote, len_velum, len_none]
weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)
criterion = CrossEntropyLoss(weight=weights)
```

### ë¬¸ì œ 4: í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ, accuracyê°€ ë‚®ìŒ

**í•´ê²°**:
```python
# train.py ìˆ˜ì •

# 1. Learning rate ì¡°ì •
config['learning_rate'] = 5e-5  # ë” ì‘ê²Œ

# 2. ë” ì˜¤ë˜ í•™ìŠµ
config['epochs'] = 100

# 3. Scheduler ë³€ê²½
config['scheduler'] = 'cosine'  # 'plateau' ëŒ€ì‹ 
```

---

## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê°€ì´ë“œ

### í•™ìŠµ í›„ í™•ì¸í•  ê²ƒë“¤

#### 1. Training History
```bash
# checkpoints/training_history.png í™•ì¸
```
- Lossê°€ ê°ì†Œí•˜ëŠ”ê°€?
- Train/Val gapì´ í¬ì§€ ì•Šì€ê°€? (ê³¼ì í•© ì²´í¬)
- Accuracyê°€ ì•ˆì •ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ”ê°€?

#### 2. Confusion Matrix
```bash
# checkpoints/confusion_matrix.png í™•ì¸
```

**ì¢‹ì€ ì˜ˆì‹œ**:
```
           OTE  Velum  None
OTE       [850    50    10]
Velum     [ 40   870    15]
None      [ 10    20   880]

â†’ ëŒ€ê°ì„ ì— ì§‘ì¤‘, ì˜¤ë¶„ë¥˜ ì ìŒ
```

**ë‚˜ìœ ì˜ˆì‹œ**:
```
           OTE  Velum  None
OTE       [600   200   200]  â† OTEë¥¼ Velum/Noneìœ¼ë¡œ ë§ì´ ì˜¤ë¶„ë¥˜
Velum     [150   700   150]
None      [300   200   500]  â† None ì„±ëŠ¥ì´ ë§¤ìš° ë‚®ìŒ

â†’ None ë°ì´í„° ì¶”ê°€ í•„ìš”
```

#### 3. Classification Report
```bash
# checkpoints/test_results.json í™•ì¸
```

```json
{
  "OTE": {
    "precision": 0.89,
    "recall": 0.91,
    "f1-score": 0.90
  },
  "Velum": {
    "precision": 0.92,
    "recall": 0.88,
    "f1-score": 0.90
  },
  "None": {
    "precision": 0.75,  â† Noneì´ ë‚®ìŒ
    "recall": 0.70,
    "f1-score": 0.72
  }
}
```

**ëª©í‘œ ì„±ëŠ¥**:
- Overall Accuracy: 85%+
- ê° í´ë˜ìŠ¤ F1-score: 80%+

---

## ğŸ’¡ Best Practices

### 1. ì „ì²˜ë¦¬ ë‹¨ê³„

âœ… **DO**:
- í•­ìƒ ì‹œê°í™” í™•ì¸ (`visualizations` í´ë”)
- ì´ìƒí•œ ë¹„ë””ì˜¤ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì œì™¸
- ì—¬ëŸ¬ detection method ë¹„êµ

âŒ **DON'T**:
- ì‹œê°í™” ì—†ì´ ë°”ë¡œ í•™ìŠµ
- ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ ë¬´ì¡°ê±´ í¬í•¨
- í•œ ê°€ì§€ ë°©ë²•ë§Œ ê³ ì§‘

### 2. í•™ìŠµ ë‹¨ê³„

âœ… **DO**:
- ì‘ì€ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì‹œì‘ (resnet18)
- ê³¼ì í•© ëª¨ë‹ˆí„°ë§ (train/val gap)
- ì •ê¸°ì ìœ¼ë¡œ checkpoint ì €ì¥

âŒ **DON'T**:
- ì²˜ìŒë¶€í„° í° ëª¨ë¸ (resnet50)
- Val accuracyë§Œ ë³´ê³  íŒë‹¨
- í•œ ë²ˆë§Œ í•™ìŠµí•˜ê³  ë

### 3. í‰ê°€ ë‹¨ê³„

âœ… **DO**:
- Confusion matrix ìƒì„¸ ë¶„ì„
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ í™•ì¸
- ì‹¤ì œ ë¹„ë””ì˜¤ë¡œ í…ŒìŠ¤íŠ¸

âŒ **DON'T**:
- Overall accuracyë§Œ í™•ì¸
- Test set ê²°ê³¼ë§Œ ë¯¿ìŒ
- í•™ìŠµ ë°ì´í„°ë¡œë§Œ í‰ê°€

---

## ğŸ“ ì¶”ê°€ ë„ì›€ë§

### ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

**Q: ë¹„ë””ì˜¤ê°€ ë„ˆë¬´ ë§ì•„ì„œ ì „ì²˜ë¦¬ê°€ ì˜¤ë˜ ê±¸ë ¤ìš”**
```bash
# ë³‘ë ¬ ì²˜ë¦¬ëŠ” ì—†ì§€ë§Œ, ì‹œê°í™”ë¥¼ ë„ë©´ ë¹ ë¦…ë‹ˆë‹¤
python preprocess_videos_robust.py --no-viz
```

**Q: íŠ¹ì • ë¹„ë””ì˜¤ë§Œ ì²˜ë¦¬í•˜ê³  ì‹¶ì–´ìš”**
```python
# preprocess_videos_robust.py ìˆ˜ì •
video_files = list(velum_path.glob('video1.mp4'))  # íŠ¹ì • íŒŒì¼ë§Œ
```

**Q: í•™ìŠµëœ ëª¨ë¸ì„ ë‹¤ë¥¸ ì»´í“¨í„°ì—ì„œ ì‚¬ìš©í•˜ë ¤ë©´?**
```bash
# ëª¨ë¸ íŒŒì¼ë§Œ ë³µì‚¬
cp checkpoints/best_model.pth /path/to/destination/

# ìƒˆ ì»´í“¨í„°ì—ì„œ
python inference.py --model best_model.pth --input video.mp4
```

**Q: í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë¶ˆê· í˜•í•´ìš” (OTE:Velum:None = 40:40:20)**
```python
# train.pyì— class weight ì¶”ê°€
weights = torch.tensor([1.0, 1.0, 2.0])  # Noneì— 2ë°° ê°€ì¤‘ì¹˜
criterion = nn.CrossEntropyLoss(weight=weights)
```

---

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

### ê³ ê¸‰ ì£¼ì œ

1. **Data Augmentation ê°•í™”**
   - Mixup, CutMix ì ìš©
   - ì˜ë£Œ ì˜ìƒ íŠ¹í™” augmentation

2. **ì•™ìƒë¸” ëª¨ë¸**
   - ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©
   - Test-Time Augmentation (TTA)

3. **Video-level Classification**
   - í”„ë ˆì„ ë‹¨ìœ„ â†’ ë¹„ë””ì˜¤ ë‹¨ìœ„
   - Temporal modeling (LSTM, Transformer)

4. **Active Learning**
   - ëª¨ë¸ì´ ë¶ˆí™•ì‹¤í•œ ìƒ˜í”Œ ì¬ë ˆì´ë¸”ë§
   - ì ì§„ì  ì„±ëŠ¥ ê°œì„ 

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì „ì²˜ë¦¬ ì „:
- [ ] dataset/OTE ì™€ dataset/Velumì— ë¹„ë””ì˜¤ ì¤€ë¹„
- [ ] requirements.txt íŒ¨í‚¤ì§€ ì„¤ì¹˜

ì „ì²˜ë¦¬ í›„:
- [ ] processed_dataset/visualizations ê·¸ë˜í”„ í™•ì¸
- [ ] ì´ìƒí•œ ë¹„ë””ì˜¤ ì—†ëŠ”ì§€ ì²´í¬
- [ ] annotations.json íŒŒì¼ ìƒì„± í™•ì¸

í•™ìŠµ í›„:
- [ ] training_history.png í™•ì¸ (ê³¼ì í•© ì²´í¬)
- [ ] confusion_matrix.png í™•ì¸
- [ ] test_results.json í™•ì¸ (í´ë˜ìŠ¤ë³„ ì„±ëŠ¥)

ë°°í¬ ì „:
- [ ] ì‹¤ì œ ë¹„ë””ì˜¤ë¡œ inference í…ŒìŠ¤íŠ¸
- [ ] ì˜¤ë¶„ë¥˜ íŒ¨í„´ ë¶„ì„
- [ ] í•„ìš”ì‹œ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘

---

**ì´ì œ ì‹œì‘í•˜ì„¸ìš”!** ğŸš€

```bash
# 1. ì „ì²˜ë¦¬
python preprocess_videos_robust.py

# 2. í•™ìŠµ
python train.py

# 3. ì¶”ë¡ 
python inference.py --model checkpoints/best_model.pth --input test.mp4 --visualize
```
