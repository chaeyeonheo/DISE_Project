"""
ìˆ˜ë©´ ë‚´ì‹œê²½ ë¹„ë””ì˜¤ ë¶„ì„ íŒŒì´í”„ë¼ì¸
- í”„ë ˆì„ ì¶”ì¶œ
- Color-based ROI ê²€ì¶œ
- íìƒ‰ ì˜ì—­ ë¶„ì„
- ì´ìƒ ì‹œì  ê°ì§€
"""

import cv2
import numpy as np
from pathlib import Path
from datetime import timedelta
import json
from tqdm import tqdm


class AirwayOcclusionAnalyzer:
    """ê¸°ë„ íìƒ‰ ë¶„ì„ê¸°"""
    
    def __init__(self, fps_extract=5, threshold_percent=30,exclude_first_seconds=2, exclude_last_seconds=3):
        """
        Args:
            fps_extract: ì´ˆë‹¹ ì¶”ì¶œí•  í”„ë ˆì„ ìˆ˜ (ì˜ˆ: 5 = 1ì´ˆì— 5í”„ë ˆì„)
            threshold_percent: íìƒ‰ ê¸°ì¤€ (ê¸°ì¤€ ëŒ€ë¹„ ëª‡ % ê°ì†Œ ì‹œ ì´ìƒìœ¼ë¡œ íŒë‹¨)
        """
        self.fps_extract = fps_extract
        self.threshold_percent = threshold_percent
        self.exclude_last_seconds = exclude_last_seconds
        self.exclude_first_seconds = exclude_first_seconds
        self.results = {
            'frames': [],
            'max_area': 0,
            'max_area_frame': 0,
            'occlusion_events': []
        }
    
    def preprocess_frame(self, frame):
        """í”„ë ˆì„ ì „ì²˜ë¦¬ (ê²€ì • ë°°ê²½ ì œê±° - ì—¬ìœ ìˆê²Œ í¬ë¡­)"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)
        
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=3)
        
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest_contour)
            
            # ğŸ”‘ í•µì‹¬ ìˆ˜ì •: ì•ˆìª½ìœ¼ë¡œ ì—¬ìœ  ë‘ê¸° (ëª¨ì„œë¦¬ ì œê±°)
            margin_percent = 0.075  # 10% ì•ˆìª½ìœ¼ë¡œ
            margin_x = int(w * margin_percent)
            margin_y = int(h * margin_percent)
            
            x = x + margin_x
            y = y + margin_y
            w = w - 2 * margin_x
            h = h - 2 * margin_y
            
            # ë²”ìœ„ ì²´í¬
            x = max(0, x)
            y = max(0, y)
            w = min(frame.shape[1] - x, w)
            h = min(frame.shape[0] - y, h)
            
            return frame[y:y+h, x:x+w], (x, y, w, h)
        
        return frame, (0, 0, frame.shape[1], frame.shape[0])
    
    def extract_roi_color_based(self, frame):
        """Color-based ROI ì¶”ì¶œ (ê¸°ë„ ë‚´ë¶€ ì–´ë‘ìš´ ì˜ì—­)"""
        if frame is None or frame.size == 0:
            return None
        
        # HSV ë³€í™˜
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # ì–´ë‘ìš´ ì˜ì—­ íƒ€ê²ŸíŒ…
        lower_dark = np.array([0, 0, 0])
        upper_dark = np.array([180, 255, 80])
        
        mask = cv2.inRange(hsv, lower_dark, upper_dark)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=3)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)
        
        # ê°€ì¥ í° ì—°ê²° ì˜ì—­
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            mask, connectivity=8
        )
        
        if num_labels > 1:
            largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
            mask_final = (labels == largest_label).astype('uint8') * 255
            area = stats[largest_label, cv2.CC_STAT_AREA]
            center = centroids[largest_label]
            
            contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                x, y, w, h = cv2.boundingRect(largest_contour)
                
                return {
                    'bbox': (x, y, w, h),
                    'area': area,
                    'center': tuple(center),
                    'mask': mask_final,
                    'contour': largest_contour
                }
        
        return None
    
    def analyze_video(self, video_path, output_dir=None):
        """
        ë¹„ë””ì˜¤ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)
        
        Returns:
            results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        video_path = Path(video_path)
        if not video_path.exists():
            raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        
        cap = cv2.VideoCapture(str(video_path))
        
        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps and fps > 0 else 0.0

        # ì•/ë’¤ íŠ¸ë¦¼ í”„ë ˆì„ ìˆ˜
        exclude_first_frames = int((fps or 0) * max(0, self.exclude_first_seconds))
        exclude_last_frames  = int((fps or 0) * max(0, self.exclude_last_seconds))

        start_frame = min(exclude_first_frames, max(0, total_frames - 1))
        end_frame_exclusive = max(start_frame, total_frames - exclude_last_frames)
        effective_total_frames = max(0, end_frame_exclusive - start_frame)

        print("\nğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´")
        print(f"  - íŒŒì¼: {video_path.name}")
        print(f"  - FPS: {fps:.2f}")
        print(f"  - ì´ í”„ë ˆì„: {total_frames}")
        print(f"  - ê¸¸ì´: {duration:.2f}ì´ˆ")
        print(f"  - ì•ìª½ ì œì™¸: {self.exclude_first_seconds}s â†’ {exclude_first_frames}í”„ë ˆì„")
        print(f"  - ë’¤ìª½ ì œì™¸: {self.exclude_last_seconds}s â†’ {exclude_last_frames}í”„ë ˆì„")
        print(f"  - ì‹¤ì œ ì²˜ë¦¬ êµ¬ê°„: [{start_frame} .. {end_frame_exclusive-1}]")
        print(f"  - ì‹¤ì œ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜: {effective_total_frames}")

        # ì‹œì‘ ìœ„ì¹˜ë¡œ ì´ë™
        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        # í”„ë ˆì„ ì¶”ì¶œ ê°„ê²©
        frame_interval = int(fps / self.fps_extract) if fps and fps > 0 else 1
        frame_interval = max(frame_interval, 1)

        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if output_dir:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            frames_dir = output_path / "frames"
            mask_dir = output_path / "masks"
            overlay_dir = output_path / "overlays"
            crop_dir = output_path / "crops"

            frames_dir.mkdir(exist_ok=True)
            mask_dir.mkdir(exist_ok=True)
            overlay_dir.mkdir(exist_ok=True)
            crop_dir.mkdir(exist_ok=True)
        
        # ë¶„ì„ ì‹œì‘
        frame_count = start_frame
        extracted_count = 0
        print(f"\nğŸ” í”„ë ˆì„ ë¶„ì„ ì‹œì‘...")
        
        # ì§„í–‰ë°”ëŠ” ì‹¤ì œ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ
        from tqdm import tqdm
        pbar = tqdm(total=(end_frame_exclusive - start_frame), desc="í”„ë ˆì„ ì²˜ë¦¬")
                
        while True:
            if frame_count >= end_frame_exclusive:
                break
            ret, frame = cap.read()
            if not ret:
                break
            
            # í”„ë ˆì„ ê°„ê²©ì— ë§ì¶° ì¶”ì¶œ
            if (frame_count - start_frame) % frame_interval == 0:
                # ì „ì²˜ë¦¬
                preprocessed, bbox = self.preprocess_frame(frame)
                
                # ROI ì¶”ì¶œ
                roi_info = self.extract_roi_color_based(preprocessed)
                
                # ì‹œê°„ ê³„ì‚°
                timestamp = frame_count / fps if fps > 0 else 0
                time_str = str(timedelta(seconds=int(timestamp)))
                
                frame_result = {
                    'frame_number': int(frame_count),
                    'extracted_index': int(extracted_count),
                    'timestamp': float(timestamp),
                    'time_str': time_str,
                    'preprocessing_bbox': tuple(map(int, bbox))
                }
                
                if roi_info:
                    frame_result.update({
                        'roi_area': float(roi_info['area']),
                        'roi_bbox': tuple(map(int, roi_info['bbox'])),
                        'roi_center': tuple(map(float, roi_info['center']))
                    })
                    
                    # ìµœëŒ€ ë©´ì  ì—…ë°ì´íŠ¸
                    if roi_info['area'] > self.results['max_area']:
                        self.results['max_area'] = roi_info['area']
                        self.results['max_area_frame'] = frame_count
                        self.results['max_area_frame_index'] = extracted_count
                    
                    # í”„ë ˆì„ ì €ì¥ (ì„ íƒì‚¬í•­)
                    if output_dir:
                        # 1. ì›ë³¸ í”„ë ˆì„
                        frame_filename = f"frame_{extracted_count:06d}.jpg"
                        cv2.imwrite(str(frames_dir / frame_filename), preprocessed)
                        frame_result['saved_path'] = str(frames_dir / frame_filename)
                        
                        # 2. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ë””ë²„ê¹…ìš©)
                        mask_filename = f"mask_{extracted_count:06d}.png"
                        cv2.imwrite(str(mask_dir / mask_filename), roi_info['mask'])
                        frame_result['mask_path'] = str(mask_dir / mask_filename)
                                                
                        # 3. ROI Crop ì´ë¯¸ì§€
                        x, y, w, h = roi_info['bbox']
                        roi_crop = preprocessed[y:y+h, x:x+w]
                        crop_filename = f"roi_crop_{extracted_count:06d}.jpg"
                        cv2.imwrite(str(crop_dir / crop_filename), roi_crop)
                        frame_result['crop_path'] = str(crop_dir / crop_filename)
                        
                        # 4. Overlay ì´ë¯¸ì§€ (ì›ë³¸ + ë°˜íˆ¬ëª… ë§ˆìŠ¤í¬)
                        overlay = preprocessed.copy()
                        mask_colored = np.zeros_like(overlay)
                        mask_colored[roi_info['mask'] > 0] = [255, 255, 0]  # ì‹œì•ˆìƒ‰/ì²­ë¡ìƒ‰ (BGR: ë…¸ë‘)
                        overlay = cv2.addWeighted(overlay, 0.9, mask_colored, 0.2, 0) # ì—¬ê¸°!!! ìˆ˜ì •!!! overlay ë¹„ìœ¨ ì¡°ì ˆ
                        
                        # ROI bbox ê·¸ë¦¬ê¸° (ë‘ê»˜ ì¦ê°€)
                        cv2.rectangle(overlay, (x, y), (x+w, y+h), (0, 255, 0), 5)
                        
                        # ì¤‘ì‹¬ì  í‘œì‹œ
                        center_x, center_y = int(roi_info['center'][0]), int(roi_info['center'][1])
                        cv2.circle(overlay, (center_x, center_y), 10, (0, 0, 255), -1)
                        
                        overlay_filename = f"overlay_{extracted_count:06d}.jpg"
                        cv2.imwrite(str(overlay_dir / overlay_filename), overlay)
                        frame_result['overlay_path'] = str(overlay_dir / overlay_filename)
                else:
                    frame_result['roi_area'] = 0
                
                self.results['frames'].append(frame_result)
                extracted_count += 1
            
            frame_count += 1
            pbar.update(1)
        
        pbar.close()
        cap.release()
        
        # íìƒ‰ ì´ë²¤íŠ¸ ê°ì§€
        self._detect_occlusion_events()
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        self.results['metadata'] = {
            'video_file': str(video_path),
            'total_frames': total_frames,
            'extracted_frames': extracted_count,
            'fps': fps,
            'duration_seconds': duration,
            'extraction_fps': self.fps_extract,
            'threshold_percent': self.threshold_percent
        }
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"  - ì¶”ì¶œëœ í”„ë ˆì„: {extracted_count}ê°œ")
        print(f"  - ìµœëŒ€ ROI ë©´ì : {self.results['max_area']:.0f} pxÂ² (í”„ë ˆì„ {self.results['max_area_frame']})")
        print(f"  - íìƒ‰ ì´ë²¤íŠ¸: {len(self.results['occlusion_events'])}ê°œ")
        
        return self.results
    
    def _detect_occlusion_events(self):
        """íìƒ‰ ì´ë²¤íŠ¸ ê°ì§€"""
        if self.results['max_area'] == 0:
            return
        
        threshold_area = self.results['max_area'] * (1 - self.threshold_percent / 100)
        
        for frame_data in self.results['frames']:
            if frame_data.get('roi_area', 0) > 0:
                area_reduction = (1 - frame_data['roi_area'] / self.results['max_area']) * 100
                frame_data['area_reduction_percent'] = area_reduction
                
                if frame_data['roi_area'] < threshold_area:
                    event = {
                        'frame_number': frame_data['frame_number'],
                        'extracted_index': frame_data['extracted_index'],
                        'timestamp': frame_data['timestamp'],
                        'time_str': frame_data['time_str'],
                        'roi_area': frame_data['roi_area'],
                        'area_reduction_percent': area_reduction,
                        'severity': self._classify_severity(area_reduction)
                    }
                    
                    # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€
                    if 'saved_path' in frame_data:
                        event['frame_path'] = frame_data['saved_path']
                    if 'overlay_path' in frame_data:
                        event['overlay_path'] = frame_data['overlay_path']
                    if 'mask_path' in frame_data:
                        event['mask_path'] = frame_data['mask_path']
                    if 'crop_path' in frame_data:
                        event['crop_path'] = frame_data['crop_path']
                    
                    self.results['occlusion_events'].append(event)
    
    def _classify_severity(self, reduction_percent):
        """íìƒ‰ ì‹¬ê°ë„ ë¶„ë¥˜"""
        if reduction_percent >= 70:
            return 'Critical'
        elif reduction_percent >= 50:
            return 'Severe'
        elif reduction_percent >= 30:
            return 'Moderate'
        else:
            return 'Mild'
    
    def save_results(self, output_path):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ ê²°ê³¼ ì €ì¥: {output_path}")


# ========== í…ŒìŠ¤íŠ¸ (ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸) ==========
if __name__ == "__main__":
    print("=" * 60)
    print("ê¸°ë„ íìƒ‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¡œ ê°„ë‹¨ í…ŒìŠ¤íŠ¸
    analyzer = AirwayOcclusionAnalyzer(fps_extract=1, threshold_percent=30)
    
    print("\nâœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"  - ì¶”ì¶œ FPS: {analyzer.fps_extract}")
    print(f"  - íìƒ‰ ê¸°ì¤€: {analyzer.threshold_percent}%")
